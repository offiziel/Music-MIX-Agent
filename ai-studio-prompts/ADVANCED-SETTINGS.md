# Advanced Settings f√ºr Google AI Studio

**Konfiguriere diese Einstellungen in AI Studio (‚öôÔ∏è Symbol):**

---

## ü§ñ MODEL SELECTION

### Empfohlen f√ºr beste Qualit√§t:
```
Model: gemini-2.0-flash-thinking-exp-1219
```
- Beste Reasoning-F√§higkeiten
- Thinking-Mode verf√ºgbar
- Optimal f√ºr komplexe VST-Parameter-Berechnungen

### Alternative (Schneller):
```
Model: gemini-1.5-flash-002
```
- Schnellere Antworten (< 2 Sekunden)
- Gut f√ºr Tests
- G√ºnstiger im Paid-Tier

### Alternative (Stabil):
```
Model: gemini-1.5-pro
```
- Bew√§hrte Qualit√§t
- Gr√∂√üerer Context (2M Tokens)
- Standard-Wahl f√ºr Production

---

## üß† THINKING LEVEL

```
Thinking Level: High
```

**Warum High?**
- Mix Mentor AI braucht pr√§zise dB/Hz/ms-Werte
- Komplexe Berechnungen f√ºr Kompressor-Ratios
- Style-spezifische Entscheidungen (Aggro vs. Emotional)

**Alternativen:**
- `Medium`: Gute Balance, schneller (f√ºr Tests)
- `Low`: Nur f√ºr einfache Anfragen (nicht empfohlen)

---

## üéöÔ∏è GENERATION SETTINGS

### Temperature
```
Temperature: 0.1
```
**Niedrig = Pr√§zise!**
- Bei 0.1: Konsistente, exakte Werte
- Bei 0.7: Kreativer, aber weniger pr√§zise
- **F√ºr Mix Mentor AI**: Immer < 0.3 nutzen!

### Max Output Tokens
```
Max Output Tokens: 4096
```
**Grund:**
- Cubase Insert Chains sind lang (8 Slots)
- Pro-Tipps + Erkl√§rungen brauchen Platz
- Minimum: 2048, Empfohlen: 4096

### Top-K
```
Top-K: 40
```
**Standard-Wert**, passt f√ºr Mix Mentor AI

### Top-P
```
Top-P: 0.95
```
**Standard-Wert**, passt f√ºr Mix Mentor AI

---

## üõ°Ô∏è SAFETY SETTINGS

```
Hate Speech: Block none
Harassment: Block none
Sexually Explicit: Block none
Dangerous Content: Block none
```

**Warum "Block none"?**
- Technische Begriffe wie "Compression", "Attack", "Punch"
- Song-Titel k√∂nnten gefiltert werden
- K√ºnstlernamen (z.B. "Bushido", "Aggro Berlin")

**Wichtig:** Mix Mentor AI generiert nur Audio-Mixing-Parameter, keine problematischen Inhalte!

---

## üì∏ MEDIA RESOLUTION

```
Media Resolution: High
```

**Optional** (falls du sp√§ter Screenshots oder Audio-Spectrograms hochladen willst)

**Alternativen:**
- `Low`: F√ºr reine Text-Eingaben ausreichend
- `Medium`: Standard-Wahl
- `High`: Beste Qualit√§t f√ºr Bilder/Audio

---

## üîß ADVANCED OPTIONS (Optional)

### Response MIME Type
```
MIME Type: text/plain
```
**Standard**, da wir Markdown-formatierte Texte erwarten

### Stop Sequences (Optional)
```
Stop Sequences: (leer lassen)
```
Nicht n√∂tig f√ºr Mix Mentor AI

### Response Schema (Optional)
```
Schema: (nicht aktivieren)
```
Wir nutzen freien Text, kein JSON-Schema n√∂tig

---

## üõ†Ô∏è TOOLS & CONTAINER

### Code Execution
```
Code Execution: ‚úÖ ON
```
**Aktivieren f√ºr:**
- Audio-Berechnungen (BPM, LUFS, Peak)
- Web Audio API Code-Generation
- Mathematische Formeln f√ºr Kompression

### Function Calling
```
Function Calling: ‚úÖ ON
```
**Aktivieren f√ºr:**
- Strukturierte Responses
- UI-Interaktionen
- API-Calls

### Grounding with Google Search
```
Grounding: ‚ùå OFF
```
**Nicht n√∂tig**, da:
- Mix Mentor AI nutzt inlined Knowledge (System Instructions)
- Keine Web-Suche erforderlich
- Spart Kosten im Paid-Tier

---

## üìä ZUSAMMENFASSUNG

**Copy & Paste diese Einstellungen:**

```yaml
# AI Studio Advanced Settings f√ºr Mix Mentor AI v3.0

model: gemini-2.0-flash-thinking-exp-1219
thinking_level: high

generation:
  temperature: 0.1
  max_output_tokens: 4096
  top_k: 40
  top_p: 0.95

safety:
  hate_speech: BLOCK_NONE
  harassment: BLOCK_NONE
  sexually_explicit: BLOCK_NONE
  dangerous_content: BLOCK_NONE

media:
  resolution: high

tools:
  code_execution: true
  function_calling: true
  grounding: false
```

---

## üí° PRO-TIPPS

### 1. Model wechseln f√ºr Tests
W√§hrend der Entwicklung: `gemini-1.5-flash-002` (schneller)
F√ºr Production: `gemini-2.0-flash-thinking-exp-1219` (beste Qualit√§t)

### 2. Temperature anpassen
- F√ºr exakte Plugin-Parameter: `0.1`
- F√ºr kreative Pro-Tipps: `0.3`
- **NIE √ºber 0.5** gehen bei Mix Mentor AI!

### 3. Thinking Level testen
Vergleiche Responses mit `medium` vs. `high`:
- `high` gibt ausf√ºhrlichere Erkl√§rungen
- `medium` ist schneller, aber weniger detailliert

### 4. Output Tokens √ºberwachen
Falls Responses abgeschnitten werden:
- Erh√∂he auf `8192` Tokens
- Oder bitte AI, kompakter zu antworten

---

## ‚úÖ Checkliste

Bevor du die App generierst:

- [ ] Model: `gemini-2.0-flash-thinking-exp-1219` ‚úì
- [ ] Thinking Level: `High` ‚úì
- [ ] Temperature: `0.1` ‚úì
- [ ] Max Tokens: `4096` ‚úì
- [ ] Safety: Alle auf `Block none` ‚úì
- [ ] Code Execution: `ON` ‚úì
- [ ] Function Calling: `ON` ‚úì
- [ ] Grounding: `OFF` ‚úì

**‚Üí Jetzt bist du ready f√ºr "Build Mode"!**
